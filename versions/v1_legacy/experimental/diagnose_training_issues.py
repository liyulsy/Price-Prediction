#!/usr/bin/env python3
"""
è¯Šæ–­è®­ç»ƒè„šæœ¬ä¸­æ–­é—®é¢˜
"""

import os
import sys
import torch
import pandas as pd
import numpy as np
from datetime import datetime
import traceback
import psutil

def check_system_resources():
    """æ£€æŸ¥ç³»ç»Ÿèµ„æº"""
    print("=== ç³»ç»Ÿèµ„æºæ£€æŸ¥ ===")
    
    # CPUå’Œå†…å­˜
    cpu_percent = psutil.cpu_percent(interval=1)
    memory = psutil.virtual_memory()
    print(f"CPUä½¿ç”¨ç‡: {cpu_percent}%")
    print(f"å†…å­˜ä½¿ç”¨: {memory.percent}% ({memory.used/1024**3:.1f}GB / {memory.total/1024**3:.1f}GB)")
    
    # GPUä¿¡æ¯
    if torch.cuda.is_available():
        print(f"CUDAå¯ç”¨: æ˜¯")
        print(f"GPUæ•°é‡: {torch.cuda.device_count()}")
        for i in range(torch.cuda.device_count()):
            props = torch.cuda.get_device_properties(i)
            memory_allocated = torch.cuda.memory_allocated(i) / 1024**3
            memory_reserved = torch.cuda.memory_reserved(i) / 1024**3
            memory_total = props.total_memory / 1024**3
            print(f"GPU {i}: {props.name}")
            print(f"  æ€»å†…å­˜: {memory_total:.1f}GB")
            print(f"  å·²åˆ†é…: {memory_allocated:.1f}GB")
            print(f"  å·²ä¿ç•™: {memory_reserved:.1f}GB")
    else:
        print("CUDAå¯ç”¨: å¦")

def check_data_files():
    """æ£€æŸ¥æ•°æ®æ–‡ä»¶"""
    print("\n=== æ•°æ®æ–‡ä»¶æ£€æŸ¥ ===")
    
    # ä»·æ ¼æ•°æ®
    price_path = 'scripts/analysis/crypto_analysis/data/processed_data/1H/all_1H.csv'
    if os.path.exists(price_path):
        try:
            df = pd.read_csv(price_path, index_col=0, parse_dates=True)
            print(f"âœ… ä»·æ ¼æ•°æ®: {df.shape}, æ—¶é—´èŒƒå›´: {df.index[0]} åˆ° {df.index[-1]}")
            
            # æ£€æŸ¥æ•°æ®è´¨é‡
            null_counts = df.isnull().sum()
            if null_counts.sum() > 0:
                print(f"âš ï¸ å‘ç°ç¼ºå¤±å€¼: {null_counts.to_dict()}")
            else:
                print("âœ… æ— ç¼ºå¤±å€¼")
                
            # æ£€æŸ¥æ•°æ®èŒƒå›´
            print(f"æ•°æ®èŒƒå›´: æœ€å°å€¼={df.min().min():.2f}, æœ€å¤§å€¼={df.max().max():.2f}")
            
        except Exception as e:
            print(f"âŒ ä»·æ ¼æ•°æ®è¯»å–é”™è¯¯: {e}")
    else:
        print(f"âŒ ä»·æ ¼æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {price_path}")
    
    # æ–°é—»æ•°æ®
    news_path = 'scripts/analysis/crypto_new_analyzer/features'
    if os.path.exists(news_path):
        files = os.listdir(news_path)
        print(f"âœ… æ–°é—»æ•°æ®: {len(files)} ä¸ªæ–‡ä»¶")
        print(f"æ–‡ä»¶åˆ—è¡¨: {files}")
    else:
        print(f"âŒ æ–°é—»æ•°æ®æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {news_path}")

def test_model_creation():
    """æµ‹è¯•æ¨¡å‹åˆ›å»º"""
    print("\n=== æ¨¡å‹åˆ›å»ºæµ‹è¯• ===")
    
    try:
        # æ·»åŠ é¡¹ç›®è·¯å¾„
        current_dir = os.path.dirname(os.path.abspath(__file__))
        project_root = os.path.join(current_dir, '.')
        sys.path.append(project_root)
        
        from models.MixModel.unified_cnn_gnn import UnifiedCnnGnn
        
        # æµ‹è¯•å‚æ•°
        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
        
        model = UnifiedCnnGnn(
            price_seq_len=60,
            num_nodes=8,
            task_type='regression',
            use_gcn=True,
            news_feature_dim=768,  # å‡è®¾çš„æ–°é—»ç‰¹å¾ç»´åº¦
            news_processed_dim=32,
            cnn_output_channels=64,
            gcn_hidden_dim=256,
            gcn_output_dim=128,
            final_mlp_hidden_dim=256,
            num_classes=2
        ).to(device)
        
        print(f"âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        
        # è®¡ç®—æ¨¡å‹å‚æ•°æ•°é‡
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        print(f"æ€»å‚æ•°æ•°: {total_params:,}")
        print(f"å¯è®­ç»ƒå‚æ•°æ•°: {trainable_params:,}")
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        batch_size = 4  # å°æ‰¹æ¬¡æµ‹è¯•
        price_seq = torch.randn(batch_size, 60, 8).to(device)
        news_features = torch.randn(batch_size, 8, 768).to(device)
        
        # åˆ›å»ºè¾¹ç´¢å¼•
        edge_index = torch.tensor([[i, j] for i in range(8) for j in range(8) if i != j]).t().to(device)
        
        with torch.no_grad():
            output = model(price_seq, edge_index, news_features=news_features)
            print(f"âœ… å‰å‘ä¼ æ’­æˆåŠŸï¼Œè¾“å‡ºå½¢çŠ¶: {output.shape}")
            
        # æ£€æŸ¥GPUå†…å­˜ä½¿ç”¨
        if torch.cuda.is_available():
            memory_used = torch.cuda.memory_allocated(device) / 1024**3
            print(f"æ¨¡å‹GPUå†…å­˜ä½¿ç”¨: {memory_used:.2f}GB")
            
    except Exception as e:
        print(f"âŒ æ¨¡å‹åˆ›å»º/æµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()

def test_data_loading():
    """æµ‹è¯•æ•°æ®åŠ è½½"""
    print("\n=== æ•°æ®åŠ è½½æµ‹è¯• ===")
    
    try:
        current_dir = os.path.dirname(os.path.abspath(__file__))
        project_root = os.path.join(current_dir, '.')
        sys.path.append(project_root)
        
        from scripts.analysis.crypto_new_analyzer.unified_dataset import UnifiedCryptoDataset, load_news_data
        
        # åŠ è½½ä»·æ ¼æ•°æ®
        price_df_raw = pd.read_csv('scripts/analysis/crypto_analysis/data/processed_data/1H/all_1H.csv', 
                                   index_col=0, parse_dates=True)
        coin_names = ['BTC', 'ETH', 'BNB', 'XRP', 'LTC', 'DOGE', 'SOL', 'AVAX']
        rename_map = {f"{coin}-USDT": coin for coin in coin_names}
        price_df = price_df_raw.rename(columns=rename_map)[coin_names]
        
        print(f"âœ… ä»·æ ¼æ•°æ®åŠ è½½æˆåŠŸ: {price_df.shape}")
        
        # åŠ è½½æ–°é—»æ•°æ®
        news_data_dict = load_news_data('scripts/analysis/crypto_new_analyzer/features', coin_names)
        print(f"âœ… æ–°é—»æ•°æ®åŠ è½½æˆåŠŸ: {len(news_data_dict)} ä¸ªå¸ç§")
        
        # åˆ›å»ºæ•°æ®é›†
        dataset = UnifiedCryptoDataset(
            price_data_df=price_df,
            news_data_dict=news_data_dict,
            seq_len=60,
            processed_news_features_path="experiments/cache/processed_news_features.pkl",
            force_recompute_news=False,
        )
        
        print(f"âœ… æ•°æ®é›†åˆ›å»ºæˆåŠŸ: {len(dataset)} ä¸ªæ ·æœ¬")
        print(f"æ–°é—»ç‰¹å¾ç»´åº¦: {dataset.news_feature_dim}")
        
        # æµ‹è¯•è·å–ä¸€ä¸ªæ ·æœ¬
        sample = dataset[0]
        print(f"âœ… æ ·æœ¬è·å–æˆåŠŸ:")
        print(f"  price_seq: {sample['price_seq'].shape}")
        print(f"  target_price: {sample['target_price'].shape}")
        if 'news_features' in sample:
            print(f"  news_features: {sample['news_features'].shape}")
            
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        traceback.print_exc()

def suggest_solutions():
    """å»ºè®®è§£å†³æ–¹æ¡ˆ"""
    print("\n=== å»ºè®®è§£å†³æ–¹æ¡ˆ ===")
    
    print("1. ğŸ”§ å‡å°‘å†…å­˜ä½¿ç”¨:")
    print("   - å‡å°æ‰¹æ¬¡å¤§å°: BATCH_SIZE = 16 æˆ– 8")
    print("   - å‡å°‘åºåˆ—é•¿åº¦: PRICE_SEQ_LEN = 30")
    print("   - å‡å°‘æ¨¡å‹å‚æ•°: é™ä½hidden_dim")
    
    print("\n2. ğŸš€ ä¼˜åŒ–è®­ç»ƒ:")
    print("   - ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯")
    print("   - å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ")
    print("   - æ¸…ç†GPUç¼“å­˜")
    
    print("\n3. ğŸ› è°ƒè¯•æ¨¡å¼:")
    print("   - æ·»åŠ try-catchåŒ…è£…è®­ç»ƒå¾ªç¯")
    print("   - ç›‘æ§å†…å­˜ä½¿ç”¨")
    print("   - ä¿å­˜æ£€æŸ¥ç‚¹")
    
    print("\n4. ğŸ“Š æ•°æ®é—®é¢˜:")
    print("   - æ£€æŸ¥æ•°æ®é¢„å¤„ç†")
    print("   - éªŒè¯æ•°æ®èŒƒå›´")
    print("   - å¤„ç†å¼‚å¸¸å€¼")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” å¼€å§‹è¯Šæ–­è®­ç»ƒé—®é¢˜...")
    print(f"æ—¶é—´: {datetime.now()}")
    
    check_system_resources()
    check_data_files()
    test_model_creation()
    test_data_loading()
    suggest_solutions()
    
    print(f"\nâœ… è¯Šæ–­å®Œæˆ!")

if __name__ == "__main__":
    main()

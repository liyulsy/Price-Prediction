#!/usr/bin/env python3
"""
è®­ç»ƒç¨³å®šæ€§åˆ†æè„šæœ¬
åˆ†æè®­ç»ƒç»“æœçš„å˜å¼‚æ€§æ¥æºå’Œæ”¹è¿›å»ºè®®
"""

import os
import sys
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.join(current_dir, '..', '..')
sys.path.append(project_root)

def analyze_training_variability():
    """åˆ†æè®­ç»ƒå˜å¼‚æ€§çš„å¯èƒ½åŸå› """
    
    print("ğŸ” è®­ç»ƒç»“æœå˜å¼‚æ€§åˆ†æ")
    print("="*60)
    
    print("\nğŸ“‹ å¯èƒ½çš„å˜å¼‚æ€§æ¥æº:")
    print("1. éšæœºæ€§æ¥æº:")
    print("   - æƒé‡åˆå§‹åŒ–éšæœºæ€§")
    print("   - æ•°æ®åŠ è½½é¡ºåºéšæœºæ€§ (DataLoader shuffle)")
    print("   - Dropoutéšæœºæ€§")
    print("   - æ‰¹æ¬¡é‡‡æ ·éšæœºæ€§")
    print("   - CUDAæ“ä½œçš„éç¡®å®šæ€§")
    
    print("\n2. æ•°æ®ç›¸å…³:")
    print("   - è®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†åˆ’åˆ†éšæœºæ€§")
    print("   - æ—¶é—´åºåˆ—æ•°æ®çš„æ—¶é—´æ•æ„Ÿæ€§")
    print("   - æ–°é—»æ•°æ®çš„å™ªå£°å’Œç¨€ç–æ€§")
    
    print("\n3. æ¨¡å‹ç›¸å…³:")
    print("   - å­¦ä¹ ç‡è°ƒåº¦å™¨çš„æ•æ„Ÿæ€§")
    print("   - æ—©åœæœºåˆ¶çš„éšæœºæ€§")
    print("   - GCNå›¾ç»“æ„çš„æ•æ„Ÿæ€§")
    
    print("\n4. è®­ç»ƒç›¸å…³:")
    print("   - è®­ç»ƒè½®æ•°ä¸è¶³")
    print("   - å±€éƒ¨æœ€ä¼˜è§£")
    print("   - æ¢¯åº¦æ¶ˆå¤±/çˆ†ç‚¸")

def suggest_improvements():
    """æä¾›æ”¹è¿›å»ºè®®"""
    
    print("\nğŸ’¡ æ”¹è¿›å»ºè®®:")
    print("="*60)
    
    print("\nğŸ¯ æé«˜ç»“æœç¨³å®šæ€§:")
    print("1. å®Œå…¨å›ºå®šéšæœºæ€§:")
    print("   âœ… å·²å®ç°: set_random_seeds() å‡½æ•°")
    print("   âœ… å·²å®ç°: å›ºå®šæ•°æ®é›†åˆ’åˆ†ç§å­")
    print("   âœ… å·²å®ç°: CUDAç¡®å®šæ€§è®¾ç½®")
    
    print("\n2. å¢åŠ è®­ç»ƒç¨³å®šæ€§:")
    print("   âœ… å·²å®ç°: å¢åŠ è®­ç»ƒè½®æ•°åˆ°50")
    print("   âœ… å·²å®ç°: æ—©åœæœºåˆ¶ (patience=10)")
    print("   ğŸ”„ å»ºè®®: ä½¿ç”¨å­¦ä¹ ç‡é¢„çƒ­")
    print("   ğŸ”„ å»ºè®®: æ¢¯åº¦è£å‰ª")
    
    print("\n3. å¤šæ¬¡è¿è¡Œç»Ÿè®¡:")
    print("   âœ… å·²å®ç°: æ‰¹é‡å®éªŒè„šæœ¬")
    print("   ğŸ”„ å»ºè®®: æ¯ä¸ªé…ç½®è‡³å°‘è¿è¡Œ10æ¬¡")
    print("   ğŸ”„ å»ºè®®: ä½¿ç”¨ç»Ÿè®¡æ˜¾è‘—æ€§æµ‹è¯•")
    
    print("\n4. æ•°æ®å¤„ç†æ”¹è¿›:")
    print("   ğŸ”„ å»ºè®®: ä½¿ç”¨å›ºå®šçš„æ—¶é—´çª—å£åˆ’åˆ†")
    print("   ğŸ”„ å»ºè®®: æ–°é—»ç‰¹å¾é™å™ª")
    print("   ğŸ”„ å»ºè®®: æ•°æ®å¢å¼ºæŠ€æœ¯")

def create_training_config_recommendations():
    """åˆ›å»ºè®­ç»ƒé…ç½®å»ºè®®"""
    
    recommendations = {
        "random_seed_control": {
            "description": "å®Œå…¨æ§åˆ¶éšæœºæ€§",
            "implemented": True,
            "code": """
def set_random_seeds(seed=42):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    os.environ['PYTHONHASHSEED'] = str(seed)
            """
        },
        
        "training_stability": {
            "description": "è®­ç»ƒç¨³å®šæ€§æ”¹è¿›",
            "implemented": "partial",
            "suggestions": [
                "å¢åŠ è®­ç»ƒè½®æ•° (50-100)",
                "ä½¿ç”¨å­¦ä¹ ç‡é¢„çƒ­",
                "æ·»åŠ æ¢¯åº¦è£å‰ª",
                "ä½¿ç”¨æ›´ç¨³å®šçš„ä¼˜åŒ–å™¨ (AdamW)",
                "è°ƒæ•´å­¦ä¹ ç‡è°ƒåº¦ç­–ç•¥"
            ]
        },
        
        "data_consistency": {
            "description": "æ•°æ®ä¸€è‡´æ€§",
            "implemented": "partial", 
            "suggestions": [
                "ä½¿ç”¨å›ºå®šçš„æ—¶é—´çª—å£åˆ’åˆ†è€Œééšæœºåˆ’åˆ†",
                "å¯¹æ–°é—»ç‰¹å¾è¿›è¡Œæ›´å¥½çš„é¢„å¤„ç†",
                "ä½¿ç”¨æ›´ç¨³å®šçš„å½’ä¸€åŒ–æ–¹æ³•",
                "è€ƒè™‘æ•°æ®æ³„æ¼é—®é¢˜"
            ]
        },
        
        "evaluation_robustness": {
            "description": "è¯„ä¼°é²æ£’æ€§",
            "implemented": True,
            "suggestions": [
                "å¤šæ¬¡è¿è¡Œå–å¹³å‡",
                "ä½¿ç”¨ç½®ä¿¡åŒºé—´",
                "ç»Ÿè®¡æ˜¾è‘—æ€§æµ‹è¯•",
                "äº¤å‰éªŒè¯"
            ]
        }
    }
    
    return recommendations

def generate_improved_training_script():
    """ç”Ÿæˆæ”¹è¿›çš„è®­ç»ƒè„šæœ¬å»ºè®®"""
    
    print("\nğŸ”§ æ”¹è¿›çš„è®­ç»ƒé…ç½®å»ºè®®:")
    print("="*60)
    
    improved_config = """
# æ”¹è¿›çš„è®­ç»ƒå‚æ•°
BATCH_SIZE = 32
EPOCHS = 100  # å¢åŠ è®­ç»ƒè½®æ•°
LEARNING_RATE = 0.001  # ç¨å¾®å¢åŠ å­¦ä¹ ç‡
WEIGHT_DECAY = 1e-4  # å¢åŠ æ­£åˆ™åŒ–
WARMUP_EPOCHS = 10  # å­¦ä¹ ç‡é¢„çƒ­
GRADIENT_CLIP_NORM = 1.0  # æ¢¯åº¦è£å‰ª
EARLY_STOPPING_PATIENCE = 15  # å¢åŠ æ—©åœè€å¿ƒ
MIN_DELTA = 1e-5  # æ›´ä¸¥æ ¼çš„æ”¹è¿›é˜ˆå€¼

# ä½¿ç”¨æ›´ç¨³å®šçš„ä¼˜åŒ–å™¨
optimizer = torch.optim.AdamW(
    model.parameters(), 
    lr=LEARNING_RATE, 
    weight_decay=WEIGHT_DECAY,
    betas=(0.9, 0.999),
    eps=1e-8
)

# å­¦ä¹ ç‡è°ƒåº¦å™¨æ”¹è¿›
scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(
    optimizer, 
    T_0=20, 
    T_mult=2, 
    eta_min=1e-6
)

# æ¢¯åº¦è£å‰ª
torch.nn.utils.clip_grad_norm_(model.parameters(), GRADIENT_CLIP_NORM)
    """
    
    print(improved_config)

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”¬ è®­ç»ƒç¨³å®šæ€§åˆ†æå’Œæ”¹è¿›å»ºè®®")
    print("="*80)
    
    # åˆ†æå˜å¼‚æ€§æ¥æº
    analyze_training_variability()
    
    # æä¾›æ”¹è¿›å»ºè®®
    suggest_improvements()
    
    # ç”Ÿæˆé…ç½®å»ºè®®
    recommendations = create_training_config_recommendations()
    
    # ç”Ÿæˆæ”¹è¿›çš„è®­ç»ƒè„šæœ¬
    generate_improved_training_script()
    
    print("\nğŸ“Š æœŸæœ›çš„å®éªŒç»“æœæ¨¡å¼:")
    print("="*60)
    print("å¦‚æœæ”¹è¿›æªæ–½æœ‰æ•ˆï¼Œä½ åº”è¯¥çœ‹åˆ°:")
    print("1. ğŸ¯ GCN + News > GCN Only â‰ˆ News Only > Baseline")
    print("2. ğŸ“‰ å„é…ç½®çš„æ ‡å‡†å·®æ˜¾è‘—é™ä½")
    print("3. ğŸ“ˆ æˆåŠŸç‡æ¥è¿‘100%")
    print("4. ğŸ”„ ç»“æœåœ¨å¤šæ¬¡è¿è¡Œé—´ä¿æŒä¸€è‡´")
    
    print("\nğŸš€ ä¸‹ä¸€æ­¥è¡ŒåŠ¨:")
    print("1. è¿è¡Œæ‰¹é‡å®éªŒ: python scripts/training/batch_experiment_timexer.py")
    print("2. åˆ†æç»“æœçš„ç»Ÿè®¡æ˜¾è‘—æ€§")
    print("3. å¦‚æœä»æœ‰å˜å¼‚æ€§ï¼Œè€ƒè™‘è¿›ä¸€æ­¥çš„æ”¹è¿›æªæ–½")

if __name__ == "__main__":
    main()

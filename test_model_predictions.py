#!/usr/bin/env python3
"""
å¿«é€Ÿæµ‹è¯•è„šæœ¬ï¼šéªŒè¯æ¨¡å‹æ˜¯å¦è¿˜å­˜åœ¨å•ä¸€é¢„æµ‹é—®é¢˜
"""

import torch
import torch.nn.functional as F
import numpy as np
from models.MixModel.unified_multiscale_timemixer_gcn import UnifiedMultiScaleTimeMixer
from dataloader.gnn_loader import create_gnn_dataloader

def test_prediction_diversity():
    """æµ‹è¯•æ¨¡å‹é¢„æµ‹çš„å¤šæ ·æ€§"""
    
    # åˆ›å»ºæµ‹è¯•é…ç½®
    class TestConfig:
        def __init__(self):
            self.seq_len = 60
            self.pred_len = 1
            self.d_model = 256
            self.d_ff = 512
            self.num_kernels = 6
            self.top_k = 5
            self.down_sampling_layers = 2
            self.down_sampling_window = 2
            self.down_sampling_method = 'avg'
            self.channel_independence = False
            self.decomp_method = 'moving_avg'
            self.moving_avg = 25
            self.dropout = 0.1
    
    config = TestConfig()
    
    # åˆ›å»ºæ¨¡å‹
    model = UnifiedMultiScaleTimeMixer(
        configs=config,
        num_features=8,  # 8ä¸ªåŠ å¯†è´§å¸
        num_classes=3,   # 3åˆ†ç±»
        task_type='classification',
        use_gcn=True,
        has_news=False,
        gcn_config={'type': 'GCN', 'hidden_dim': 128, 'num_layers': 2}
    )
    
    model.eval()
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    batch_size = 32
    seq_len = 60
    num_features = 8
    
    x_enc = torch.randn(batch_size, seq_len, num_features)
    x_mark_enc = torch.randn(batch_size, seq_len, 4)  # æ—¶é—´ç‰¹å¾
    
    # åˆ›å»ºç®€å•çš„å›¾ç»“æ„
    edge_index = torch.tensor([[0, 1, 2, 3], [1, 2, 3, 0]], dtype=torch.long)
    
    with torch.no_grad():
        # å¤šæ¬¡å‰å‘ä¼ æ’­æµ‹è¯•
        predictions = []
        for _ in range(5):
            output = model(x_enc, x_mark_enc, edge_index=edge_index)
            predictions.append(output.cpu().numpy())
    
    # åˆ†æé¢„æµ‹å¤šæ ·æ€§
    predictions = np.array(predictions)  # [5, batch_size, num_features, num_classes]
    
    print("ğŸ” é¢„æµ‹å¤šæ ·æ€§åˆ†æ:")
    print(f"é¢„æµ‹å½¢çŠ¶: {predictions.shape}")
    
    # æ£€æŸ¥æ¯ä¸ªæ ·æœ¬çš„é¢„æµ‹åˆ†å¸ƒ
    for i in range(min(3, batch_size)):  # æ£€æŸ¥å‰3ä¸ªæ ·æœ¬
        sample_preds = predictions[:, i, :, :]  # [5, num_features, num_classes]
        
        print(f"\næ ·æœ¬ {i+1}:")
        for j in range(num_features):
            feature_preds = sample_preds[:, j, :]  # [5, num_classes]
            
            # è®¡ç®—é¢„æµ‹çš„æ ‡å‡†å·®
            pred_std = np.std(feature_preds, axis=0)
            pred_mean = np.mean(feature_preds, axis=0)
            
            # åº”ç”¨softmaxè·å¾—æ¦‚ç‡
            probs = F.softmax(torch.tensor(feature_preds), dim=-1).numpy()
            prob_std = np.std(probs, axis=0)
            
            print(f"  ç‰¹å¾ {j}: åŸå§‹è¾“å‡ºstd={pred_std}, æ¦‚ç‡std={prob_std}")
            
            # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰é¢„æµ‹éƒ½ç›¸åŒ
            if np.all(pred_std < 1e-6):
                print(f"    âš ï¸  ç‰¹å¾ {j} é¢„æµ‹å®Œå…¨ç›¸åŒ!")
            else:
                print(f"    âœ… ç‰¹å¾ {j} é¢„æµ‹æœ‰å˜åŒ–")
    
    # æ•´ä½“ç»Ÿè®¡
    all_preds_flat = predictions.reshape(-1, predictions.shape[-1])
    overall_std = np.std(all_preds_flat, axis=0)
    
    print(f"\nğŸ“Š æ•´ä½“ç»Ÿè®¡:")
    print(f"æ‰€æœ‰é¢„æµ‹çš„æ ‡å‡†å·®: {overall_std}")
    print(f"é¢„æµ‹æ˜¯å¦æœ‰å¤šæ ·æ€§: {'æ˜¯' if np.any(overall_std > 1e-3) else 'å¦'}")
    
    return predictions

if __name__ == "__main__":
    print("ğŸ§ª å¼€å§‹æµ‹è¯•æ¨¡å‹é¢„æµ‹å¤šæ ·æ€§...")
    try:
        predictions = test_prediction_diversity()
        print("\nâœ… æµ‹è¯•å®Œæˆ!")
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

import torch
import torch.nn as nn
from ..BaseModel.wpmixer import WPMixerCore
from models.BaseModel.improved_gcn import create_gcn_from_config

class MLPBlock(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim, dropout=0.3):
        super().__init__()
        self.fc1 = nn.Linear(input_dim, hidden_dim)
        self.fc2 = nn.Linear(hidden_dim, hidden_dim)
        self.fc3 = nn.Linear(hidden_dim, output_dim)
        self.dropout = nn.Dropout(dropout)
        self.layer_norm1 = nn.LayerNorm(hidden_dim)
        self.layer_norm2 = nn.LayerNorm(hidden_dim)

    def forward(self, x):
        # First layer
        h1 = self.fc1(x)
        h1 = torch.relu(h1)
        h1 = self.layer_norm1(h1)
        h1 = self.dropout(h1)

        # Second layer with residual connection
        h2 = self.fc2(h1)
        h2 = torch.relu(h2)
        h2 = self.layer_norm2(h2)
        h2 = self.dropout(h2)
        h2 = h2 + h1  # Residual connection

        # Output layer
        out = self.fc3(h2)
        return out

class UnifiedWPMixer(nn.Module):
    def __init__(self,
                 configs,
                 gcn_hidden_dim,
                 gcn_output_dim,
                 # --- Optional Components ---
                 use_gcn: bool = False,
                 gcn_config: str = 'improved_gelu',  # æ–°å¢ï¼šGCNé…ç½®é€‰æ‹©
                 news_feature_dim: int = None,
                 news_processed_dim: int = 32,
                 # --- MLP and Output ---
                 mlp_hidden_dim: int = 256,
                 num_classes: int = 2):
        super(UnifiedWPMixer, self).__init__()

        self.task_type = configs.task_type
        self.use_gcn = use_gcn
        self.gcn_config = gcn_config
        self.has_news = news_feature_dim is not None and news_feature_dim > 0
        self.num_classes = num_classes


        # 1. WPMixeræ ¸å¿ƒ - æ—¶é—´åºåˆ—ç‰¹å¾æå–
        self.wpmixer = WPMixerCore(
            input_length=configs.input_length,
            pred_length=configs.pred_length,
            wavelet_name=configs.wavelet_name,
            level=configs.level,
            batch_size=32,  # ä½¿ç”¨åŠ¨æ€æ‰¹æ¬¡å¤§å°æé«˜ç¨³å®šæ€§
            channel=1,  # å•å¸ç§ç‹¬ç«‹å¤„ç†
            d_model=configs.d_model,
            dropout=configs.dropout,
            embedding_dropout=configs.dropout,
            tfactor=configs.tfactor,
            dfactor=configs.dfactor,
            patch_len=configs.patch_len,
            patch_stride=configs.patch_stride,
            no_decomposition=configs.no_decomposition,
            use_amp=configs.use_amp
        )

        # è®¡ç®—åŸºç¡€ç‰¹å¾ç»´åº¦ï¼ˆWPMixerè¾“å‡ºç»´åº¦ï¼‰
        # ç›´æ¥ä½¿ç”¨pred_lengthä½œä¸ºç‰¹å¾ç»´åº¦ï¼Œä¸æŠ•å½±åˆ°d_model
        base_features_dim = configs.pred_length

        # --- Optional News Processor ---
        if self.has_news:
            self.news_processor = MLPBlock(
                input_dim=news_feature_dim,
                hidden_dim=news_processed_dim * 2,
                output_dim=news_processed_dim,
                dropout=configs.dropout if hasattr(configs, 'dropout') else 0.3
            )
            # è®¡ç®—èåˆåçš„ç‰¹å¾ç»´åº¦
            features_dim = base_features_dim + news_processed_dim
        else:
            self.news_processor = None
            features_dim = base_features_dim

        # --- Optional GCN ---
        if self.use_gcn:
            # ä½¿ç”¨æ”¹è¿›çš„GCNé…ç½®
            print(f"ğŸ”§ UnifiedWPMixerä½¿ç”¨GCNé…ç½®: {self.gcn_config}")
            self.gcn = create_gcn_from_config(self.gcn_config, features_dim, gcn_hidden_dim, gcn_output_dim)
            mlp_input_dim = gcn_output_dim  # MLP takes output from GCN
        else:
            self.gcn = None
            mlp_input_dim = features_dim  # MLP takes features directly


        # 5. æœ€ç»ˆé¢„æµ‹å±‚
        if self.task_type == 'regression':
            final_layer_output_dim = 1 # Predict one continuous value
        else: # 'classification'
            final_layer_output_dim = num_classes

        self.mlp = MLPBlock(
            input_dim=mlp_input_dim,
            hidden_dim=mlp_hidden_dim,
            output_dim=final_layer_output_dim,
            dropout=configs.dropout if hasattr(configs, 'dropout') else 0.3
        )


    def forward(self, price_data, edge_index=None, edge_weight=None, news_features=None):
        """
        å‰å‘ä¼ æ’­

        Args:
            price_data: [batch_size, seq_len, num_coins] ä»·æ ¼åºåˆ—æ•°æ®
            edge_index: [2, num_edges] GCNè¾¹ç´¢å¼•ï¼ˆå¯é€‰ï¼‰
            edge_weight: [num_edges] GCNè¾¹æƒé‡ï¼ˆå¯é€‰ï¼‰
            news_features: [batch_size, num_coins, news_dim] æ–°é—»ç‰¹å¾ï¼ˆå¯é€‰ï¼‰

        Returns:
            predictions: [batch_size, num_coins, num_classes/1] é¢„æµ‹ç»“æœ
        """
        batch_size, seq_len, num_coins = price_data.shape

        # 1. WPMixeræ—¶é—´åºåˆ—ç‰¹å¾æå– - ä¼˜åŒ–çš„é€å¸ç§å¤„ç†
        # è½¬ç½®ä¸º [batch_size, num_coins, seq_len]
        price_transposed = price_data.transpose(1, 2)  # [batch_size, num_coins, seq_len]

        # ä½¿ç”¨åˆ—è¡¨æ¨å¯¼å¼å’Œtorch.stackè¿›è¡Œé«˜æ•ˆå¤„ç†
        wpmixer_outputs = []
        for coin_idx in range(num_coins):
            # WPMixerè¾“å‡º: [batch_size, 1, pred_length]
            wpmixer_out = self.wpmixer(price_transposed[:, coin_idx, :].unsqueeze(1))
            # å»æ‰é€šé“ç»´åº¦ï¼Œä¿ç•™ pred_length ä½œä¸ºç‰¹å¾ç»´åº¦
            coin_features = wpmixer_out.squeeze(1)  # [batch_size, pred_length]
            wpmixer_outputs.append(coin_features)

        # åˆå¹¶æ‰€æœ‰å¸ç§çš„ç‰¹å¾ [batch_size, num_coins]
        wpmixer_features = torch.stack(wpmixer_outputs, dim=1)  # [batch_size, num_coins, pred_length]

        # # # æ‰©å±•ç‰¹å¾ç»´åº¦ä»¥åŒ¹é…åç»­å¤„ç†
        # if len(wpmixer_features.shape) == 2:
        #     wpmixer_features = wpmixer_features.unsqueeze(-1)  # [batch_size, num_coins, 1]

        # 2. èåˆæ–°é—»ç‰¹å¾ï¼ˆå¯é€‰ï¼‰
        if self.has_news and self.news_processor is not None and news_features is not None:
            # å¤„ç†æ–°é—»ç‰¹å¾ [batch_size, num_coins, news_dim] -> [batch_size, num_coins, news_processed_dim]
            news_processed = self.news_processor(news_features)
            # æ‹¼æ¥ç‰¹å¾ [batch_size, num_coins, d_model + news_processed_dim]
            combined_features = torch.cat([wpmixer_features, news_processed], dim=-1)
        else:
            combined_features = wpmixer_features

        # 3. GCNå›¾å·ç§¯å¢å¼ºï¼ˆå¯é€‰ï¼‰
        if self.use_gcn and self.gcn is not None and edge_index is not None:
            # é‡å¡‘ä¸ºå›¾æ•°æ®æ ¼å¼ [batch_size * num_coins, feature_dim]
            graph_features = combined_features.reshape(batch_size * num_coins, -1)

            # æ‰©å±•è¾¹ç´¢å¼•ä»¥å¤„ç†æ‰¹æ¬¡æ•°æ®
            batch_edge_index = []
            batch_edge_weight = []
            for b in range(batch_size):
                offset = b * num_coins
                batch_edge_index.append(edge_index + offset)
                if edge_weight is not None:
                    batch_edge_weight.append(edge_weight)

            batch_edge_index = torch.cat(batch_edge_index, dim=1)
            if edge_weight is not None:
                batch_edge_weight = torch.cat(batch_edge_weight, dim=0)
            else:
                batch_edge_weight = None

            # GCNå¤„ç†
            gcn_features = self.gcn(graph_features, batch_edge_index, batch_edge_weight)

            # é‡å¡‘å› [batch_size, num_coins, gcn_output_dim]
            final_features = gcn_features.reshape(batch_size, num_coins, -1)
        else:
            final_features = combined_features

        # 4. æœ€ç»ˆé¢„æµ‹ - ä½¿ç”¨MLP
        B, N, F = final_features.shape
        mlp_in = final_features.view(B * N, F)
        mlp_out = self.mlp(mlp_in)
        predictions = mlp_out.view(B, N, -1)

        # 5. æ ¹æ®ä»»åŠ¡ç±»å‹è°ƒæ•´è¾“å‡ºå½¢çŠ¶
        if self.task_type == 'regression':
            # å›å½’ä»»åŠ¡ï¼šé¢„æµ‹æ¯ä¸ªå¸ç§çš„ä»·æ ¼ï¼Œè¾“å‡º [batch_size, num_coins]
            predictions = predictions.squeeze(-1)  # ç§»é™¤æœ€åä¸€ä¸ªç»´åº¦
        else:
            # åˆ†ç±»ä»»åŠ¡ï¼šé¢„æµ‹æ¯ä¸ªå¸ç§çš„ç±»åˆ«ï¼Œè¾“å‡º [batch_size, num_coins, num_classes]
            pass  # ä¿æŒåŸæœ‰å½¢çŠ¶

        return predictions



















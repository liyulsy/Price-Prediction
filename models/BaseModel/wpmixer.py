#!/usr/bin/env python3
"""
WPMixer (Wavelet Patch Mixer) åŸºç¡€æ¨¡å‹
ä»åŸå§‹WPMixeré¡¹ç›®æ¬ç§»çš„æ ¸å¿ƒå®ç°

ä¸»è¦åŠŸèƒ½ï¼š
1. å°æ³¢åˆ†è§£å’Œé‡æ„
2. è¡¥ä¸åµŒå…¥
3. MLPæ··åˆ
4. å¤šåˆ†è¾¨ç‡åˆ†æ”¯å¤„ç†

ä½œè€…ï¼šåŸºäºWPMixeré¡¹ç›®æ¬ç§»
"""

import torch
import torch.nn as nn

import numpy as np
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from utils.RevIN import RevIN
from models.layers.decomposition import Decomposition
from models.layers.wpmixer_layers import ResolutionBranch

class WPMixerCore(nn.Module):
    """WPMixeræ ¸å¿ƒæ¨¡å‹ - ä»åŸå§‹é¡¹ç›®æ¬ç§»ï¼Œç§»é™¤æœ€åçš„é¢„æµ‹å±‚"""

    def __init__(self,
                 input_length = None,
                 pred_length = None,
                 wavelet_name = None,
                 level = None,
                 batch_size = None,
                 channel = None,
                 d_model = None,
                 dropout = None,
                 embedding_dropout = None,
                 tfactor = None,
                 dfactor = None,
                 device = None,
                 patch_len = None,
                 patch_stride = None,
                 no_decomposition = None,
                 use_amp = None):

        super(WPMixerCore, self).__init__()
        self.input_length = input_length
        self.pred_length = pred_length
        self.wavelet_name = wavelet_name
        self.level = level
        self.batch_size = batch_size
        self.channel = channel
        self.d_model = d_model
        self.dropout = dropout
        self.embedding_dropout = embedding_dropout
        self.device = device if device is not None else torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.no_decomposition = no_decomposition
        self.tfactor = tfactor
        self.dfactor = dfactor
        self.use_amp = use_amp

        self.Decomposition_model = Decomposition(input_length = self.input_length,
                                        pred_length = self.pred_length,
                                        wavelet_name = self.wavelet_name,
                                        level = self.level,
                                        batch_size = self.batch_size,
                                        channel = self.channel,
                                        d_model = self.d_model,
                                        tfactor = self.tfactor,
                                        dfactor = self.dfactor,
                                        device = self.device,
                                        no_decomposition = self.no_decomposition,
                                        use_amp = self.use_amp)

        self.input_w_dim = self.Decomposition_model.input_w_dim # list of the length of the input coefficient series
        self.pred_w_dim = self.Decomposition_model.pred_w_dim # list of the length of the predicted coefficient series

        self.patch_len = patch_len
        self.patch_stride = patch_stride

        # (m+1) number of resolutionBranch
        self.resolutionBranch = nn.ModuleList([ResolutionBranch(input_seq = self.input_w_dim[i],
                                                           pred_seq = self.pred_w_dim[i],
                                                           batch_size = self.batch_size,
                                                           channel = self.channel,
                                                           d_model = self.d_model,
                                                           dropout = self.dropout,
                                                           embedding_dropout = self.embedding_dropout,
                                                           tfactor = self.tfactor,
                                                           dfactor = self.dfactor,
                                                           patch_len = self.patch_len,
                                                           patch_stride = self.patch_stride) for i in range(len(self.input_w_dim))])

        self.revin = RevIN(self.channel, eps=1e-5, affine = True, subtract_last = False)

    def forward(self, xL):
        '''
        Parameters
        ----------
        xL : Look back window: [Batch, look_back_length, channel]

        Returns
        -------
        features : æå–çš„ç‰¹å¾è¡¨ç¤ºï¼Œç§»é™¤äº†æœ€åçš„é¢„æµ‹å±‚
        '''

        # RevIN æœŸæœ›è¾“å…¥æ ¼å¼: [batch, seq_len, num_features]
        # ä½† xL çš„æ ¼å¼æ˜¯: [batch, num_features, seq_len]
        xL_for_revin = xL.transpose(1, 2)  # [batch, seq_len, num_features]
        x = self.revin(xL_for_revin, 'norm')  # [batch, seq_len, num_features]
        x = x.transpose(1, 2) # [batch, num_features, seq_len]

        # xA: approximation coefficient series,
        # xD: detail coefficient series
        # yA: predicted approximation coefficient series
        # yD: predicted detail coefficient series

        xA, xD = self.Decomposition_model.transform(x)

        yA = self.resolutionBranch[0](xA)
        yD = []
        for i in range(len(xD)):
            yD_i = self.resolutionBranch[i + 1](xD[i])
            yD.append(yD_i)

        # æ‰§è¡Œé€†å°æ³¢å˜æ¢é‡æ„é¢„æµ‹åºåˆ—
        reconstructed_x = self.Decomposition_model.inv_transform(yA, yD)

        # æ‰§è¡Œåå½’ä¸€åŒ– (RevIN denormalization)
        reconstructed_x = reconstructed_x.transpose(1, 2) # -> [B, L_pred, C]
        reconstructed_x = reconstructed_x[:, -self.pred_length:, :]  # å…ˆè£å‰ªæ—¶é—´ç»´åº¦
        denorm_x = self.revin(reconstructed_x, 'denorm')
        denorm_x = denorm_x.transpose(1, 2) # -> [B, C, L_pred]

        # è¿”å›æ­£ç¡®è£å‰ªçš„ç»“æœ
        return denorm_x
    
        #     # å¯¹äºç‰¹å¾æå–ï¼Œæˆ‘ä»¬éœ€è¦æ›´ä¸°å¯Œçš„è¡¨ç¤º
        # # ä¸è¿›è¡Œé€†å˜æ¢ï¼Œè€Œæ˜¯ç›´æ¥ä½¿ç”¨åˆ†è§£åçš„ç‰¹å¾

        # # å°†æ‰€æœ‰åˆ†è¾¨ç‡çš„ç‰¹å¾è¿æ¥èµ·æ¥
        # all_features = [yA]  # ä½é¢‘ç‰¹å¾
        # all_features.extend(yD)  # é«˜é¢‘ç‰¹å¾

        # # å°†æ‰€æœ‰ç‰¹å¾åœ¨æœ€åä¸€ä¸ªç»´åº¦ä¸Šè¿æ¥
        # # yA: [batch, channel, pred_length], yD: [batch, channel, pred_length]
        # concatenated_features = torch.cat(all_features, dim=-1)  # [batch, channel, total_features]

        # # è½¬æ¢ä¸ºæœŸæœ›çš„æ ¼å¼: [batch, channel, d_model]
        # # ä½¿ç”¨å¹³å‡æ± åŒ–æˆ–çº¿æ€§å˜æ¢æ¥è·å¾—å›ºå®šçš„d_modelç»´åº¦
        # if concatenated_features.size(-1) != self.d_model:
        #     # ä½¿ç”¨è‡ªé€‚åº”å¹³å‡æ± åŒ–æ¥è°ƒæ•´æœ€åä¸€ä¸ªç»´åº¦
        #     concatenated_features = F.adaptive_avg_pool1d(
        #         concatenated_features, self.d_model
        #     )  # [batch, channel, d_model]

        # return concatenated_features  # [batch, channel, d_model]


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    print("ğŸ§ª æµ‹è¯•WPMixeræ ¸å¿ƒæ¨¡å‹...")

    # åˆ›å»ºæ¨¡å‹å‚æ•°
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    model = WPMixerCore(
        input_length=96,
        pred_length=24,
        wavelet_name='db4',
        level=3,
        batch_size=32,
        channel=8,
        d_model=128,
        dropout=0.1,
        embedding_dropout=0.1,
        tfactor=2,
        dfactor=4,
        device=device,
        patch_len=16,
        patch_stride=8,
        no_decomposition=False,
        use_amp=False
    )

    # åˆ›å»ºæµ‹è¯•æ•°æ®
    batch_size = 32
    x = torch.randn(batch_size, 96, 8)

    # å‰å‘ä¼ æ’­
    try:
        output = model(x)
        print(f"âœ… è¾“å…¥å½¢çŠ¶: {x.shape}")
        print(f"âœ… è¾“å‡ºå½¢çŠ¶: {output.shape}")
        print(f"âœ… æ¨¡å‹å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
        print("ğŸ‰ WPMixeræ ¸å¿ƒæ¨¡å‹æµ‹è¯•é€šè¿‡ï¼")
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        print("ğŸ’¡ è¿™å¯èƒ½æ˜¯å› ä¸ºç¼ºå°‘pytorch_waveletsåº“ï¼Œæ¨¡å‹ä¼šä½¿ç”¨ç®€åŒ–çš„åˆ†è§£æ–¹æ³•")
